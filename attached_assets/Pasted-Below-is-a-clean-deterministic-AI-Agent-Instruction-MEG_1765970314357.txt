Below is a clean, deterministic AI Agent Instruction (MEGA PROMPT) designed specifically for Replit Agent Mode.

It is written to:
	‚Ä¢	Avoid ambiguity
	‚Ä¢	Prevent agent drift
	‚Ä¢	Enforce naming, ordering, and scope
	‚Ä¢	Be executable step-by-step
	‚Ä¢	Protect compliance language

You can paste this verbatim into Replit Agent Mode.

‚∏ª

üö® REFLECTIVAI ‚Äî REPLIT AGENT MODE INSTRUCTIONS

UI, IA, EI METRICS, FRAMEWORKS, AND COACHING LOGIC UPDATE

ROLE

You are an expert product engineer + UX implementer working inside an existing AI sales enablement application (ReflectivAI).
Your task is to update UI structure, navigation, naming, EI metrics presentation, and coaching logic exactly as specified below.

You must not invent new features, rename anything not listed, or alter backend logic unless explicitly instructed.

‚∏ª

HARD CONSTRAINTS (DO NOT VIOLATE)
	‚Ä¢	‚ùå Do NOT introduce new metrics
	‚Ä¢	‚ùå Do NOT remove existing metrics
	‚Ä¢	‚ùå Do NOT infer emotions, intent, or personality
	‚Ä¢	‚ùå Do NOT change scoring algorithms
	‚Ä¢	‚ùå Do NOT alter compliance logic
	‚Ä¢	‚ùå Do NOT expose SQL or backend logic to reps
	‚Ä¢	‚úÖ All language must be explainable, compliant, and observable
	‚Ä¢	‚úÖ Use provided copy verbatim where specified

‚∏ª

PHASE 0 ‚Äî NAVIGATION & INFORMATION ARCHITECTURE (MANDATORY)

LEFT NAV ‚Üí CUSTOMIZATIONS (REORDER + RENAME)

Update Customizations section to the following exact order:
	1.	EI Metrics
	2.	Selling and Coaching Frameworks
	3.	Data and Reports
	4.	Knowledge Base

Rules:
	‚Ä¢	‚ÄúTools‚Äù must be renamed to Customizations
	‚Ä¢	‚ÄúHeuristics‚Äù must be renamed to Selling and Coaching Frameworks
	‚Ä¢	‚ÄúSQL Translator‚Äù must be renamed to Data and Reports
	‚Ä¢	Naming must be consistent across:
	‚Ä¢	Sidebar
	‚Ä¢	Dashboard
	‚Ä¢	Headers
	‚Ä¢	Tooltips

‚∏ª

PHASE 1 ‚Äî EI METRICS STRUCTURE (CORE VS EXTENDED)

EI METRICS SCREEN (UNDER CUSTOMIZATIONS)

Create an EI Metrics configuration screen with two sections:

‚∏ª

SECTION A ‚Äî CORE METRICS (DEFAULT / DEMO)

Label:

Core EI Metrics (Recommended)

These four metrics only must be surfaced by default across:
	‚Ä¢	Dashboard
	‚Ä¢	Role-Play Performance Analysis
	‚Ä¢	Project cards
	‚Ä¢	Demo views

Core Metrics (EXACT LIST):
	1.	Empathy Accuracy
	2.	Discovery Depth
	3.	Clarity
	4.	Adaptability

Each metric must display:
	‚Ä¢	Name
	‚Ä¢	Score (1‚Äì5)
	‚Ä¢	Expandable explanation panel
	‚Ä¢	Coaching feedback (existing logic, unchanged)

‚∏ª

SECTION B ‚Äî EXTENDED METRICS (OPTIONAL)

Label:

Additional EI Metrics (Configurable)

Include remaining metrics:
	‚Ä¢	Compliance
	‚Ä¢	Active Listening
	‚Ä¢	Objection Handling
	‚Ä¢	Confidence
	‚Ä¢	Action Insight
	‚Ä¢	Resilience

Rules:
	‚Ä¢	Metrics can be toggled on/off
	‚Ä¢	Metrics can be weighted (if already supported)
	‚Ä¢	Metrics must indicate where they are used:
	‚Ä¢	AI Coach
	‚Ä¢	Role Play Simulator
	‚Ä¢	Exercises
	‚Ä¢	Reporting

‚∏ª

GOVERNANCE CALLOUT (REQUIRED COPY ‚Äî USE VERBATIM)

‚ÄúReflectivAI evaluates emotionally intelligent behaviors using observable communication signals.
It does not assess personality, intent, or emotional state.‚Äù

‚∏ª

PHASE 2 ‚Äî LEGAL-APPROVED EI METRIC DEFINITIONS

Use the following definitions verbatim wherever EI metric explanations appear:

Empathy Accuracy

Measures how effectively the representative acknowledged and reflected the HCP‚Äôs expressed concerns, priorities, and constraints based on observable conversation cues.

Discovery Depth

Measures the extent to which the representative asked relevant follow-up questions to validate assumptions and understand the HCP‚Äôs context before responding.

Clarity

Measures how clearly and appropriately the representative translated information into relevant, context-specific messaging aligned to the HCP‚Äôs decision considerations.

Adaptability

Measures how effectively the representative adjusted their communication approach in response to new information or signals during the interaction.

Compliance

Adherence to approved labeling and avoidance of off-label discussion.

Active Listening

Demonstrated attention through accurate paraphrasing and referencing of stated concerns.

Objection Handling

Acknowledgment and response to objections using appropriate, non-promotional framing.

Confidence

Clear and composed delivery without overreliance on generalized claims.

Action Insight

Ability to propose appropriate next steps based on discussion content.

Resilience

Maintenance of composure and professionalism under challenge.

‚∏ª

PHASE 3 ‚Äî DASHBOARD & QUICK ACTION ALIGNMENT

QUICK ACTIONS (MANDATORY)

Ensure the following four quick actions appear:
	‚Ä¢	Together on the Dashboard
	‚Ä¢	Together at the top of the Sidebar

Exact order:
	1.	Dashboard
	2.	AI Coach
	3.	Role Play Simulator
	4.	Exercises

Naming must match exactly across all locations.

‚∏ª

PHASE 4 ‚Äî AI COACH & ROLE PLAY CONFIGURATION

DROPDOWN STRUCTURE (INDUSTRY STANDARD)

Apply this structure to AI Coach and Role Play Simulator:

Dropdown 1: Disease State
Dropdown 2: Specialty (filtered by Disease State)
	‚Ä¢	Cardiologist
	‚Ä¢	Endocrinologist
	‚Ä¢	NP
	‚Ä¢	PA
	‚Ä¢	Family Practice
	‚Ä¢	Internal Medicine

Dropdown 3: HCP Category
	‚Ä¢	KOL
	‚Ä¢	Prescriber / Treater
	‚Ä¢	Non-Prescribing
	‚Ä¢	Low Engagement

Dropdown 4: Influence & Decision Drivers
	‚Ä¢	Evidence-Based
	‚Ä¢	Patient-Centric
	‚Ä¢	Risk-Averse
	‚Ä¢	Guideline-Anchored

‚∏ª

PHASE 5 ‚Äî PERSONA & SIMULATION RULES

AI Coach
	‚Ä¢	‚ùå No named HCPs
	‚Ä¢	‚ùå No fixed personas
	‚Ä¢	‚úÖ Use decision signals only

Role Play Simulator
	‚Ä¢	‚úÖ Named HCPs allowed
	‚Ä¢	‚úÖ Simulates real-world conversation
	‚Ä¢	üîí Lock HCP category
	‚Ä¢	üîÑ Vary influence signal mix

‚∏ª

PHASE 6 ‚Äî COACHING FEEDBACK LOGIC (LANGUAGE RULES)

REQUIRED LANGUAGE PATTERN

AI feedback must reference signals, not labels.

‚ùå Bad:

‚ÄúThis HCP is risk-averse.‚Äù

‚úÖ Good:

‚ÄúRisk-cautious and guideline-anchored signals were present.‚Äù

‚∏ª

EXAMPLE FEEDBACK (USE AS TEMPLATE)

‚ÄúYou acknowledged concerns but moved quickly to generalized data.
Based on guideline-anchored and risk-cautious signals, consider validating workflow constraints before introducing outcomes.‚Äù

‚∏ª

PHASE 7 ‚Äî DATA & REPORTS (FORMERLY SQL TRANSLATOR)

Rename SQL Translator ‚Üí Data and Reports

MANAGER-LEVEL CALLOUT (USE VERBATIM)

‚ÄúData and Reports supports performance trends, coaching insights, and reporting for managers and leadership.
This feature is not intended for daily sales representative workflows.‚Äù

Add:
	‚Ä¢	Manager Access Only badge
	‚Ä¢	Hide from rep-level views

‚∏ª

PHASE 8 ‚Äî FRAMEWORK POSITIONING (FOUNDATIONAL COPY)

Wherever frameworks are explained, use this sentence verbatim:

‚ÄúReflectivAI incorporates behavioral models, decision-influence frameworks, and emotional intelligence principles to support compliant, adaptive, and human-centered engagement.‚Äù

‚∏ª

FINAL VALIDATION CHECKLIST (MUST PASS)

Before completion, confirm:
	‚Ä¢	‚úÖ EI Metrics appear before Selling & Coaching Frameworks
	‚Ä¢	‚úÖ Only 4 EI metrics appear in demo views
	‚Ä¢	‚úÖ All 10 metrics are configurable
	‚Ä¢	‚úÖ No persona-based labeling exists
	‚Ä¢	‚úÖ All copy is explainable and compliant
	‚Ä¢	‚úÖ Sidebar mirrors dashboard
	‚Ä¢	‚úÖ No backend logic altered unintentionally

‚∏ª

OUTPUT REQUIREMENT

At completion, provide:
	1.	List of files modified
	2.	Summary of changes by phase
	3.	Confirmation that no prohibited actions occurred

‚∏ª

END OF INSTRUCTIONS

‚∏ª

If you want next, I can:
	‚Ä¢	Convert this into a VS Code Copilot Agent prompt
	‚Ä¢	Break this into atomic tickets
	‚Ä¢	Add acceptance criteria per phase
	‚Ä¢	Write a rollback plan if agent mode fails mid-execution

Just say the word.